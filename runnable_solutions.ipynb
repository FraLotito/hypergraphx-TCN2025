{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12aaa9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "\n",
    "def build_hypergraph_hgx() -> Hypergraph:\n",
    "    hg = Hypergraph()\n",
    "    # 8 nodes\n",
    "    hg.add_nodes(list(\"ABCDEFGH\"))\n",
    "    # 5 hyperedges (mixed sizes, overlapping allowed)\n",
    "    hg.add_edges([\n",
    "        (\"A\",\"B\",\"C\"),\n",
    "        (\"B\",\"C\",\"D\"),\n",
    "        (\"A\",\"D\"),\n",
    "        (\"E\",\"F\",\"G\"),\n",
    "        (\"A\",\"E\",\"H\"),\n",
    "    ])\n",
    "    return hg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0563d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = build_hypergraph_hgx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f69008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "\n",
    "def edge_size_distribution(hg: Hypergraph) -> Dict[int, int]:\n",
    "    # HGX returns a Counter-like mapping; normalize to plain dict (sorted for determinism).\n",
    "    return dict(sorted(hg.distribution_sizes().items()))\n",
    "\n",
    "def node_degrees(hg: Hypergraph) -> Dict[str, int]:\n",
    "    return {str(u): hg.degree(u) for u in hg.get_nodes()}\n",
    "\n",
    "def top_k_by_degree(hg: Hypergraph, k: int) -> List[str]:\n",
    "    deg = node_degrees(hg)\n",
    "    return [u for u, _ in sorted(deg.items(), key=lambda x: (-x[1], x[0]))[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e65079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 1, 3: 4}\n",
      "{'A': 3, 'B': 2, 'C': 2, 'D': 2, 'E': 2, 'F': 1, 'G': 1, 'H': 1}\n",
      "['A', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "print(edge_size_distribution(H))\n",
    "print(node_degrees(H))\n",
    "print(top_k_by_degree(H, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0231d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Set, Tuple\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "\n",
    "def incident_edges(hg: Hypergraph, node: str) -> List[Tuple[str, ...]]:\n",
    "    # Convert each incident edge to a sorted tuple; return a globally sorted list.\n",
    "    edges = [tuple(sorted(map(str, e))) for e in hg.get_incident_edges(node)]\n",
    "    return sorted(edges)\n",
    "\n",
    "def neighbors_by_size(hg: Hypergraph, node: str, size: int) -> Set[str]:\n",
    "    return set(map(str, hg.get_neighbors(node, size=size)))\n",
    "\n",
    "def largest_component_size(hg: Hypergraph) -> int:\n",
    "    return hg.largest_component_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "123bb41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'B', 'C'), ('A', 'D'), ('A', 'E', 'H')]\n",
      "{'B', 'C', 'E', 'H'}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(incident_edges(H, \"A\"))\n",
    "print(neighbors_by_size(H, \"A\", size=3))\n",
    "print(largest_component_size(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04d9fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "\n",
    "def sub_of_size(hg: Hypergraph, size: int) -> Hypergraph:\n",
    "    return hg.subhypergraph_by_orders(sizes=[size])\n",
    "\n",
    "def is_uniform(hg: Hypergraph) -> bool:\n",
    "    return hg.is_uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7d16ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypergraph with 8 nodes and 4 edges.\n",
      "Distribution of hyperedge sizes: {3: 4}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "H2 = sub_of_size(H, size=3)\n",
    "print(H2)\n",
    "print(is_uniform(H2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d21e80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Set\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "from collections import defaultdict\n",
    "\n",
    "def clique_projection_neighbors(hg: Hypergraph) -> Dict[str, Set[str]]:\n",
    "    nbrs: Dict[str, Set[str]] = defaultdict(set)\n",
    "    # Ensure all nodes appear as keys\n",
    "    for u in hg.get_nodes():\n",
    "        nbrs[str(u)]  # touch\n",
    "\n",
    "    # For each node, every other member in an incident edge is a neighbor\n",
    "    for u in hg.get_nodes():\n",
    "        u = str(u)\n",
    "        for e in hg.get_incident_edges(u):\n",
    "            members = list(map(str, e))\n",
    "            for v in members:\n",
    "                if v != u:\n",
    "                    nbrs[u].add(v)\n",
    "                    nbrs[v].add(u)  # symmetry\n",
    "    return {u: set(vs) for u, vs in nbrs.items()}\n",
    "\n",
    "def clique_projection_degree(hg: Hypergraph) -> Dict[str, int]:\n",
    "    nbrs = clique_projection_neighbors(hg)\n",
    "    return {u: len(vs) for u, vs in nbrs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3971d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': {'H', 'E', 'C', 'D', 'B'}, 'B': {'A', 'D', 'C'}, 'C': {'A', 'D', 'B'}, 'D': {'A', 'B', 'C'}, 'E': {'A', 'G', 'H', 'F'}, 'F': {'G', 'E'}, 'G': {'E', 'F'}, 'H': {'A', 'E'}}\n",
      "{'A': 5, 'B': 3, 'C': 3, 'D': 3, 'E': 4, 'F': 2, 'G': 2, 'H': 2}\n"
     ]
    }
   ],
   "source": [
    "print(clique_projection_neighbors(H))\n",
    "print(clique_projection_degree(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e09d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Set\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "\n",
    "def edge_size_buckets(hg: Hypergraph) -> Dict[int, int]:\n",
    "    return dict(sorted(hg.distribution_sizes().items()))\n",
    "\n",
    "def nodes_covered_by_size(hg: Hypergraph) -> Dict[int, Set[str]]:\n",
    "    out: Dict[int, Set[str]] = {}\n",
    "    for e in hg.get_edges():\n",
    "        s = len(e)\n",
    "        out.setdefault(s, set()).update(map(str, e))\n",
    "    return {k: set(sorted(v)) for k, v in sorted(out.items())}\n",
    "\n",
    "def coverage_share_by_size(hg: Hypergraph) -> Dict[int, float]:\n",
    "    total = float(hg.num_nodes()) if hg.num_nodes() else 1.0\n",
    "    covered = nodes_covered_by_size(hg)\n",
    "    return {s: len(v)/total for s, v in covered.items()}\n",
    "\n",
    "def cumulative_coverage_share(hg: Hypergraph, ascending: bool = True) -> Dict[int, float]:\n",
    "    sizes = sorted(edge_size_buckets(hg).keys(), reverse=not ascending)\n",
    "    total = float(hg.num_nodes()) if hg.num_nodes() else 1.0\n",
    "    seen: Set[str] = set()\n",
    "    out: Dict[int, float] = {}\n",
    "    by_size = nodes_covered_by_size(hg)\n",
    "    for s in sizes:\n",
    "        seen |= by_size.get(s, set())\n",
    "        out[s] = len(seen)/total\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f94a469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 1, 3: 4}\n",
      "{2: {'A', 'D'}, 3: {'E', 'F', 'A', 'G', 'B', 'H', 'C', 'D'}}\n",
      "{2: 0.25, 3: 1.0}\n",
      "{2: 0.25, 3: 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(edge_size_buckets(H))\n",
    "print(nodes_covered_by_size(H))\n",
    "print(coverage_share_by_size(H))\n",
    "print(cumulative_coverage_share(H, ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9531dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "\n",
    "def neighbors_by_size(hg: Hypergraph, node: str, size: int) -> Set[str]:\n",
    "    return set(map(str, hg.get_neighbors(node, size=size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33e3d784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B', 'C', 'E', 'H'}\n"
     ]
    }
   ],
   "source": [
    "print(neighbors_by_size(H, \"A\", size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bc21823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Set, Tuple\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "from collections import defaultdict\n",
    "\n",
    "EdgeKey = Tuple[str, ...]\n",
    "Incidence = Dict[str, Set[EdgeKey]]\n",
    "\n",
    "def _edge_key(e) -> EdgeKey:\n",
    "    return tuple(sorted(map(str, e)))\n",
    "\n",
    "def dual_nodes(hg: Hypergraph) -> Set[EdgeKey]:\n",
    "    return { _edge_key(e) for e in hg.get_edges() }\n",
    "\n",
    "def dual_incidence(hg: Hypergraph) -> Incidence:\n",
    "    inc: Incidence = defaultdict(set)\n",
    "    for e in hg.get_edges():\n",
    "        ek = _edge_key(e)\n",
    "        for u in map(str, e):\n",
    "            inc[u].add(ek)\n",
    "    return {u: set(sorted(v)) for u, v in sorted(inc.items())}\n",
    "\n",
    "def dual_degrees(hg: Hypergraph) -> Dict[EdgeKey, int]:\n",
    "    return { _edge_key(e): len(e) for e in hg.get_edges() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc5f094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': {('A', 'B', 'C'), ('A', 'E', 'H'), ('A', 'D')}, 'B': {('A', 'B', 'C'), ('B', 'C', 'D')}, 'C': {('A', 'B', 'C'), ('B', 'C', 'D')}, 'D': {('B', 'C', 'D'), ('A', 'D')}, 'E': {('E', 'F', 'G'), ('A', 'E', 'H')}, 'F': {('E', 'F', 'G')}, 'G': {('E', 'F', 'G')}, 'H': {('A', 'E', 'H')}}\n"
     ]
    }
   ],
   "source": [
    "print(dual_incidence(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06a2be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "from itertools import combinations\n",
    "\n",
    "EdgeKey = Tuple[str, ...]\n",
    "\n",
    "def _ek(e) -> EdgeKey:\n",
    "    return tuple(sorted(map(str, e)))\n",
    "\n",
    "def _jaccard(a: set, b: set) -> float:\n",
    "    u = len(a|b)\n",
    "    return (len(a&b)/u) if u else 0.0\n",
    "\n",
    "def topk_edge_jaccard(hg: Hypergraph, k: int) -> List[Tuple[EdgeKey, EdgeKey, float]]:\n",
    "    edges = [set(map(str, e)) for e in hg.get_edges()]\n",
    "    keys  = [_ek(e) for e in hg.get_edges()]\n",
    "    triples: List[Tuple[EdgeKey, EdgeKey, float]] = []\n",
    "    for (i, j) in combinations(range(len(edges)), 2):\n",
    "        e1, e2 = keys[i], keys[j]\n",
    "        if e2 < e1:  # enforce e1 < e2\n",
    "            e1, e2 = e2, e1\n",
    "            a, b = edges[j], edges[i]\n",
    "        else:\n",
    "            a, b = edges[i], edges[j]\n",
    "        triples.append((e1, e2, _jaccard(a, b)))\n",
    "    triples.sort(key=lambda t: (-t[2], t[0], t[1]))\n",
    "    return triples[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d948ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('A', 'B', 'C'), ('B', 'C', 'D'), 0.5), (('A', 'B', 'C'), ('A', 'D'), 0.25), (('A', 'D'), ('A', 'E', 'H'), 0.25)]\n"
     ]
    }
   ],
   "source": [
    "print(topk_edge_jaccard(H, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "274debe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, Tuple, List\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "\n",
    "EdgeKey = Tuple[str, ...]\n",
    "\n",
    "def _ek(e) -> EdgeKey:\n",
    "    return tuple(sorted(map(str, e)))\n",
    "\n",
    "def filter_edges_by_min_overlap(hg: Hypergraph, tau: int) -> Hypergraph:\n",
    "    edges: List[Set[str]] = [set(map(str, e)) for e in hg.get_edges()]\n",
    "    keep = [False]*len(edges)\n",
    "    for i, Ei in enumerate(edges):\n",
    "        best = 0\n",
    "        for j, Ej in enumerate(edges):\n",
    "            if i == j: continue\n",
    "            best = max(best, len(Ei & Ej))\n",
    "            if best >= tau:\n",
    "                keep[i] = True\n",
    "                break\n",
    "    new_hg = Hypergraph()\n",
    "    # Add only nodes that appear in kept edges\n",
    "    kept_edges = [tuple(sorted(e)) for i, e in enumerate(edges) if keep[i]]\n",
    "    if kept_edges:\n",
    "        node_set = sorted(set().union(*kept_edges))\n",
    "        new_hg.add_nodes(node_set)\n",
    "        new_hg.add_edges(kept_edges)\n",
    "    return new_hg\n",
    "\n",
    "def remaining_edge_keys(hg: Hypergraph) -> Set[EdgeKey]:\n",
    "    return { _ek(e) for e in hg.get_edges() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72fa4d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypergraph with 8 nodes and 5 edges.\n",
      "Distribution of hyperedge sizes: {3: 4, 2: 1}\n"
     ]
    }
   ],
   "source": [
    "print(filter_edges_by_min_overlap(H, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f3c735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "\n",
    "def components(hg: Hypergraph) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Return connected components as sorted lists of node labels (strings),\n",
    "    using HGX's built-in connected components.\n",
    "    \"\"\"\n",
    "    comps = hg.connected_components()  # HGX API\n",
    "    return sorted([sorted(map(str, comp)) for comp in comps])\n",
    "\n",
    "def largest_component_size(hg: Hypergraph) -> int:\n",
    "    \"\"\"\n",
    "    Return the size (in nodes) of the largest connected component,\n",
    "    using HGX's built-in method.\n",
    "    \"\"\"\n",
    "    return int(hg.largest_component_size())  # HGX API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af388e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(components(H))\n",
    "print(largest_component_size(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dcebe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from math import log\n",
    "from collections import defaultdict\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "\n",
    "def participation_by_size(hg: Hypergraph) -> Dict[str, Dict[int, int]]:\n",
    "    out: Dict[str, Dict[int, int]] = defaultdict(lambda: defaultdict(int))\n",
    "    for e in hg.get_edges():\n",
    "        s = len(e)\n",
    "        for u in map(str, e):\n",
    "            out[u][s] += 1\n",
    "    # Normalize to plain dicts (sorted for determinism)\n",
    "    return {u: {k: v for k, v in sorted(sz.items())} for u, sz in sorted(out.items())}\n",
    "\n",
    "def participation_entropy(hg: Hypergraph) -> Dict[str, float]:\n",
    "    part = participation_by_size(hg)\n",
    "    ent: Dict[str, float] = {}\n",
    "    for u, hist in part.items():\n",
    "        total = sum(hist.values())\n",
    "        if total == 0:\n",
    "            ent[u] = 0.0\n",
    "            continue\n",
    "        H = 0.0\n",
    "        for c in hist.values():\n",
    "            p = c / total\n",
    "            H -= p * log(p)\n",
    "        ent[u] = H\n",
    "    return ent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8e07bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': {2: 1, 3: 2}, 'B': {3: 2}, 'C': {3: 2}, 'D': {2: 1, 3: 1}, 'E': {3: 2}, 'F': {3: 1}, 'G': {3: 1}, 'H': {3: 1}}\n"
     ]
    }
   ],
   "source": [
    "print(participation_by_size(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fd6989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Iterable, List\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "\n",
    "def _degree_map(hg: Hypergraph) -> Dict[str, int]:\n",
    "    return {str(u): hg.degree(u) for u in hg.get_nodes()}\n",
    "\n",
    "def _rank_from_degrees(deg: Dict[str, int]) -> Dict[str, int]:\n",
    "    order = sorted(deg.items(), key=lambda x: (-x[1], x[0]))  # degree desc, id asc\n",
    "    return {u: i + 1 for i, (u, _) in enumerate(order)}\n",
    "\n",
    "def degree_rank(hg: Hypergraph) -> Dict[str, int]:\n",
    "    return _rank_from_degrees(_degree_map(hg))\n",
    "\n",
    "def add_edge_and_rank_changes(hg: Hypergraph, new_edge: Iterable[str], top: int = 3) -> List[str]:\n",
    "    # Degrees before\n",
    "    deg0 = _degree_map(hg)\n",
    "\n",
    "    # Degrees after: +1 for each unique node in the new edge (including new nodes)\n",
    "    deg1 = deg0.copy()\n",
    "    for u in set(map(str, new_edge)):    # dedupe just in case\n",
    "        deg1[u] = deg1.get(u, 0) + 1\n",
    "\n",
    "    # Ranks before/after\n",
    "    r0 = _rank_from_degrees(deg0)\n",
    "    r1 = _rank_from_degrees(deg1)\n",
    "\n",
    "    # Compare on the union of nodes (so brand-new nodes are included)\n",
    "    universe = sorted(set(deg1) | set(r0))\n",
    "    diffs = [(u, abs(r0.get(u, len(universe)) - r1.get(u, len(universe)))) for u in universe]\n",
    "    diffs.sort(key=lambda x: (-x[1], x[0]))  # biggest change first, tie-break by id\n",
    "\n",
    "    return [u for u, _ in diffs[:top]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a18a2eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8}\n"
     ]
    }
   ],
   "source": [
    "print(degree_rank(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fc0a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from hypergraphx.readwrite import load_hypergraph\n",
    "\n",
    "def load_counts(path: str) -> Tuple[int, int]:\n",
    "    hg = load_hypergraph(path)\n",
    "    return int(hg.num_nodes()), int(hg.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53f14fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12306, 7060)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'datasets/coauth-cs-NeurIPS.json'\n",
    "print(load_counts(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f26e916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Dict\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "from hypergraphx.generation.random import random_hypergraph\n",
    "\n",
    "SIZES = [2, 3, 4, 5, 6]\n",
    "\n",
    "def _edges_by_size_for_majority(total_min: int, target_size: int) -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Build a histogram with a strict majority for `target_size` and totals >= total_min.\n",
    "    We use a small baseline for non-target sizes and assign the rest to the target.\n",
    "    \"\"\"\n",
    "    non_target = [s for s in SIZES if s != target_size]\n",
    "    baseline = 1 * len(non_target)  # 1 edge for each non-target size\n",
    "    # ensure target strictly more than any other; allocate a cushion above the minimum\n",
    "    target_count = max(total_min - baseline, 1) + 2  # +2 cushion\n",
    "    total = target_count + baseline\n",
    "    hist = {s: (1 if s in non_target else target_count) for s in SIZES}\n",
    "    # If we want to slightly exceed total_min to be robust to any generator de-duplication,\n",
    "    # this histogram intentionally produces >= total_min edges.\n",
    "    return hist\n",
    "\n",
    "def generate_five_majority(n_min: int = 10, e_min: int = 10, seed: Optional[int] = None) -> List[Hypergraph]:\n",
    "    hgs: List[Hypergraph] = []\n",
    "    # Keep nodes exactly n_min (spec allows >=; tests only require >=)\n",
    "    n = n_min\n",
    "    for idx, target in enumerate(SIZES):\n",
    "        edges_by_size = _edges_by_size_for_majority(e_min, target)\n",
    "        sd = None if seed is None else seed + idx\n",
    "        hg = random_hypergraph(num_nodes=n, num_edges_by_size=edges_by_size, seed=sd)\n",
    "        hgs.append(hg)\n",
    "    return hgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92b3cee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypergraph with 10 nodes and 12 edges.\n",
      "Distribution of hyperedge sizes: {2: 8, 3: 1, 4: 1, 5: 1, 6: 1}\n",
      "Hypergraph with 10 nodes and 12 edges.\n",
      "Distribution of hyperedge sizes: {2: 1, 3: 8, 4: 1, 5: 1, 6: 1}\n",
      "Hypergraph with 10 nodes and 12 edges.\n",
      "Distribution of hyperedge sizes: {2: 1, 3: 1, 4: 8, 5: 1, 6: 1}\n",
      "Hypergraph with 10 nodes and 12 edges.\n",
      "Distribution of hyperedge sizes: {2: 1, 3: 1, 4: 1, 5: 8, 6: 1}\n",
      "Hypergraph with 10 nodes and 12 edges.\n",
      "Distribution of hyperedge sizes: {2: 1, 3: 1, 4: 1, 5: 1, 6: 8}\n"
     ]
    }
   ],
   "source": [
    "HS = generate_five_majority(n_min=10, e_min=10, seed=42)\n",
    "for hg in HS:\n",
    "    print(hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66828a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, Set\n",
    "from hypergraphx.core.hypergraph import Hypergraph\n",
    "import random\n",
    "\n",
    "def _is_connected(hg: Hypergraph) -> bool:\n",
    "    try:\n",
    "        return int(hg.largest_component_size()) == hg.num_nodes()\n",
    "    except AttributeError:\n",
    "        comps = hg.connected_components()\n",
    "        return max((len(c) for c in comps), default=0) == hg.num_nodes()\n",
    "\n",
    "def grow_until_connected(n: int = 20, seed: Optional[int] = None) -> Tuple[Hypergraph, int]:\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    hg = Hypergraph()\n",
    "    nodes = [str(i) for i in range(n)]\n",
    "    hg.add_nodes(nodes)\n",
    "\n",
    "    seen: Set[frozenset] = set()  # frozensets of node labels\n",
    "\n",
    "    while not _is_connected(hg):\n",
    "        s = rng.randint(2, 4)          # edge size ∈ {2,3,4}\n",
    "        members = tuple(sorted(rng.sample(nodes, s)))  # sample without replacement\n",
    "        key = frozenset(members)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        hg.add_edges([members])\n",
    "\n",
    "        # (Optional) safety: avoid pathological loops\n",
    "        if len(seen) > 50_000 and not _is_connected(hg):\n",
    "            break\n",
    "\n",
    "    return hg, hg.num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b2beb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypergraph with 10 nodes and 12 edges.\n",
      "Distribution of hyperedge sizes: {4: 4, 2: 6, 3: 2}\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "H_GROW, E_H_GROW = grow_until_connected(n=10, seed=42)\n",
    "print(H_GROW)\n",
    "print(E_H_GROW)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
